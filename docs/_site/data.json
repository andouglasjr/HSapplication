[{"sort":1,"permalink":"//","layout":"default","title":"Holographic System for Machine Learning Approaches (HolSys-ML): Beta Version","content":"<h1 id=\"holographic-system-for-machine-learning-approaches-holsys-ml-beta-version\">Holographic System for Machine Learning Approaches (HolSys-ML): Beta Version</h1>\n\n<p>The HolSys-ML is a complete holographic system developed by <a href=\"http://www.natalnet.br\">Natalnet Laboratory Network</a> (Brazil) and <a href=\"https://www.isasi.cnr.it/\">Institute of Applied Sciences and Intelligent Systems - ISASI</a> (Italy) to identify and classify microparticles in water samples. The system was designed to be used by scientists and researches in order to make easier the studies of particles using holography techniques and deep learning trained models. In this page is detailed all the steps to build a HolSys and it is available the Web Application developed to work with the system to perform all need steps to reconstruct the hologram and classify it using ML.</p>\n\n<h2 id=\"holsys-hardware\">HolSys Hardware</h2>\n\n<p>The holographic system is composed by optical and structural components that have been designed to make the setup easier for different sort of applications. All the documentation to clone the HolSys is detailed <a href=\"\">here</a>.</p>\n\n<h2 id=\"hswebapp\">HSWebApp</h2>\n\n<p>The HSWebApp was developed to be used with the HolSys but can be used for any holographic device that acquire the hologram using a digital camera. This application is able to make the follow steps:</p>\n\n<ol>\n <li><strong>Acquisition</strong>: The device camera plugged in the computer is accessed directly by the browser and the hologram can be acquired and uploaded to the server. It is also possible to use acquired holograms saved in the “/saved_holograms” folder. In this case, .png, .jpeg, and .bmp images and .mat file are supported.</li>\n <li><strong>Processing</strong>: In this step is possible to apply some image filters, like bright and contrast, to improve the fringes partners.</li>\n <li><strong>Reconstruction</strong>: Once the hologram was acquired and processed, it is possible to make its reconstruction with pixel size, wavelength and plane Z range parameters. Besides that, to off-axis setup, a manual spatial filter can be applied to isolate only the real image for the reconstruction. The reconstruction step realizes the propagation (using the HoloPy library modified) and the autofocusing using Tamura Coefficient technique and return the intensity and phase of the reconstructed hologram.</li>\n <li><strong>Segmentation:</strong> Depending on how the samples is disposed in the image, it is necessary to perform the separation to be inserting on the machine learning model. This is performed using Otsu algorithm and image fill.</li>\n <li><strong>Machine Learning</strong>: In this last step, the user can upload some ML models and use it to classify the test samples for their application. More than one model can be used in a ensemble model approach.</li>\n</ol>\n\n<p>The web application codes are available on <a href=\"\">github</a>. To use this code access the <a href=\"\">Get Started</a> section and to know more about the application access <a href=\"\">HSWebApp Doc</a>.</p>\n\n<h2 id=\"credits-and-citation\">Credits and Citation</h2>\n\n<p>Please, visit the <a href=\"\">Credits and Citation</a> page to see how to credit this system and how to help to improve it.</p>\n\n<h2 id=\"license\">License</h2>\n\n<p>The theme is available as open source under the terms of the MIT License.</p>\n","dir":"/","name":"README.md","path":"README.md","url":"/"},{"sort":1,"layout":"default","title":"Knowing the System","content":"<h1 id=\"knowing-the-system\">Knowing the System</h1>\n\n<p>The HolSys-ML is able to acquire holographic images of water samples using a holographic system, make the reconstruction using a web application or any numerical tool, and perform the classification using Deep Learning models. The system is shown in the image below.</p>\n\n<p align=\"center\">\n<img src=\"/images/image_system.jpg\" width=\"200\" />\n</p>\n\n<p>The distances between the components are the main point in the system setup. As this system was thought to be used mainly in scientific proposes, an important characteristic that is important to highlight is the ability to change the position of the components easily, making it adaptable relying on the application. Besides that, it is possible to adapt the system to be used to different samples size or to improve the acquired hologram by making little changes in these distances.</p>\n\n<p>This system is composed by optical and structural components. The firsts, when correctly placed, generate the hologram in the camera plane, whereas the other allow the movement of the optical components in the configuration step. The optical and structural components used to build this system are detailed in the section <a href=\"components.html\">Components</a>. Some of these components are build in a 3D printer and are detailed in the section <a href=\"3d_design.html\">3D Design</a>.</p>\n\n","dir":"/holsys_hardware/","name":"knowing_system.md","path":"holsys_hardware/knowing_system.md","url":"/holsys_hardware/knowing_system.html"},{"sort":1,"layout":"default","title":"Acquisition","content":"<h1 id=\"acquisition\">Acquisition</h1>\n\n<p>In the acquisition step is possible to acquire the image from the camera directly plugged in the computer (<strong>WARNING: It is important to check if the browser that access the server is updated to use getUserMedia, if not the acquisition step will no work.</strong>) or upload a hologram already acquired. All the holograms should be placed in the <strong>saved_holograms</strong> folder. Besides <strong>jpeg, png, and bmp</strong> images, the system accepts files with <strong>.mat</strong> extension. This kind of file is largely used in holography and hold more information data, like wavelength and pixel size.</p>\n\n<p align=\"center\">\n<img src=\"/images/acquisition_screen.png\" width=\"900\" />\n</p>\n\n<p>If the selected files is .mat the system will request the hologram attribute within this file. In this case, the processing step is skipped and go directly to reconstruction. Otherwise, being an image selected, the user can process it before reconstruct it.</p>\n\n<h2 id=\"tree-folder\">Tree Folder</h2>\n\n<p>A label called “experiment name” is used to organize all the images and saved data obtained over all the processes. When the hologram is acquired or chosen by a list of files, it is generated hologram metadata. This metadata is a DataArray type that gathers all information passed by the user or generated by the system. The metadata is composed of a 2D-array that holds the hologram image, the coordinates of these arrays and wavelength, pixel size, and experiment name attributes.</p>\n\n<p>The tree folder with each result of each step is</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">APP</span>\n<span class=\"o\">|-</span> <span class=\"n\">Static</span>\n    <span class=\"o\">|-</span> <span class=\"n\">ML</span><span class=\"o\">-</span><span class=\"n\">Models</span> <span class=\"c1\">#Folder holding the trained models used in the classification step\n</span>    <span class=\"o\">|-</span> <span class=\"n\">Saved_Holograms</span> <span class=\"c1\">#Folder holding saved holograms that can be used rather than camera acquisition\n</span>    <span class=\"o\">|-</span> <span class=\"n\">Results</span>\n        <span class=\"o\">|-</span> <span class=\"n\">Experiment_Name</span>\n            <span class=\"o\">|-</span> <span class=\"n\">Classification_Results</span> <span class=\"c1\">#Confusion matrix and graphs generated in the classification step\n</span>            <span class=\"o\">|-</span> <span class=\"n\">Hologram</span> <span class=\"c1\">#Hologram that will be used in the reconstruction\n</span>            <span class=\"o\">|-</span> <span class=\"n\">Processed_Hologram</span> <span class=\"c1\">#Hologram modified by the processing step\n</span>            <span class=\"o\">|-</span> <span class=\"n\">Reconstructed_Hologram</span> <span class=\"c1\">#FFT and, Intensity and Phases reconstructions\n</span>            <span class=\"o\">|-</span> <span class=\"n\">Segmented_Images</span> <span class=\"c1\">#Images obtained from the segmentation\n</span>            <span class=\"o\">|-</span> <span class=\"n\">STL_Files</span>  <span class=\"c1\">#Microscope 3D STL file\n</span></code></pre>  </div></div>\n","dir":"/hs_webapp/","name":"acquisition.md","path":"hs_webapp/acquisition.md","url":"/hs_webapp/acquisition.html"},{"sort":2,"layout":"default","title":"Components","content":"<h1 id=\"components\">Components</h1>\n\n<p>The positions of the components can be modified, and to do so it is very important to a robust structure with high precision. Worth to remind that in a holographic setup a tiny variation in these positions can mean defocused images, alias and replica phenomena, or even unfeasible reconstructions. In order to overcome these issues was designed an aluminum structure and used professional optical components were acquired on <a href=\"\">ThorLabs Store</a>.</p>\n\n<h2 id=\"optical-components\">Optical Components</h2>\n\n<p>The table below shows the basic optical components used to assemble the interferometric microscope device.</p>\n\n<table>\n <thead>\n <tr>\n <th>Components</th>\n <th>Description</th>\n <th>Specification</th>\n </tr>\n </thead>\n <tbody>\n <tr>\n <td>Source Light</td>\n <td>Collimated Laser-Diode-Pumped DPSS Laser Module</td>\n <td>Wavelength = 532 nm, w = 4.5 mW, Round Beam, Ø11 mm Housing.</td>\n </tr>\n <tr>\n <td>Battery</td>\n <td>Battery Pack for CPS Laser Diodes</td>\n <td>5 VDC, 10 000 mAh</td>\n </tr>\n <tr>\n <td>Beam Expander</td>\n <td> </td>\n <td>Wavelength = 532 nm, Expansion Ratio: 5X, Size: 70.5 mm, Transmission: &gt;96%</td>\n </tr>\n <tr>\n <td>Microchannel Chip</td>\n <td> </td>\n <td>Channel Volume: 11.8 micro liter$, Channel Width: 1.0 micrometer, Channel Depth: 0.2 micro liter</td>\n </tr>\n <tr>\n <td>Grating</td>\n <td> </td>\n <td> </td>\n </tr>\n <tr>\n <td>Lens</td>\n <td>Mounted Geltech™ Lens</td>\n <td>f=6.24mm, AR Coated 1050nm-1550nm</td>\n </tr>\n <tr>\n <td>Digital Camera</td>\n <td>See3CAM_CU55M</td>\n <td>5MP Monochrome, Pixel Size: 2.2 micrometer</td>\n </tr>\n </tbody>\n</table>\n\n<h2 id=\"structural-components\">Structural Components</h2>\n\n<p>The structural components make possible the right placement of the optical components and a robust system base to minimize the vibrations effects in the hologram acquisition.</p>\n\n<h3 id=\"system-base\">System Base</h3>\n\n<p>The base of the system was designed to be robust, in order to keep the optical components aligned correctly and to try deal with the vibrations of these components. The figure below depicts the drawing of the system, indicating the profile used and the assemble.</p>\n\n<p align=\"center\">\n<img src=\"/images/alluminium_drawing.jpg\" width=\"600\" />\n</p>\n\n<p>All the system is formed by 12 aluminum bars with a v-slot profile. This profile makes easier the assemble and allows the exchange of the pieces, letting the system adaptable. Of those 12 bars, 7 bars of 250mm are used to the structure bases; 2 bars of 200mm to the vertical laser support; 3 bars of 150mm to the horizontal laser support; and a plate 150x80x3mm to the laser holder.</p>\n\n<h3 id=\"optical-components-holders\">Optical Components Holders</h3>\n\n<p>To move the optical components are used professional components that are fixed on the system base and are able to change the positions of these components, making the system able to change according to application and easily adjustable to acquire better holograms. The table below show these components.</p>\n\n<table>\n <thead>\n <tr>\n <th>Components</th>\n <th>Description</th>\n <th>Specification</th>\n </tr>\n </thead>\n <tbody>\n <tr>\n <td>Lens</td>\n <td>XR25-XZ Assembly Kit <br /> XR25-B1 Baseplate} <br /> XR25P 25 mm Travel Stage <br /> ST1XY-S - Translator (micrometer drives)</td>\n <td>These components allow perform the right displacements<br /> in the lens in all directions.</td>\n </tr>\n <tr>\n <td>Camera</td>\n <td>XR25-XZ Assembly Kit<br />XR25-B1 Baseplate<br />XR25P 25 mm Travel Stage<br />CH1A - Fixed Cylindrical Mounts}</td>\n <td>These components allow perform the right camera displacement <br /> in the Z direction. The CH1 is an adapted component that can be replaced <br /> for any holder that possibilities fix the camera to baseplate.</td>\n </tr>\n <tr>\n <td>Grating</td>\n <td>FP01 - Plate Holders</td>\n <td>This holder is a adapted component to fix the grating to aluminum <br />structure and also can be replaced for a similar component.</td>\n </tr>\n </tbody>\n</table>\n\n<p>Then, the final 3D structure assembled is</p>\n\n<p align=\"center\">\n<img src=\"/images/3d_model.jpg\" width=\"450\" />\n</p>\n\n<h3 id=\"designed-components\">Designed Components</h3>\n\n<p>As the lens diameter is smaller than the structural component aperture used to hold the lens, a little piece was designed to assemble correctly these two components. Besides that, in the experiment setup, it was found one problem related to the lens holder that it needed to make another piece to solve. Basically, the acquired lens holder has a little gap between the holder structure and the lens. When the laser beam impinges in the lens, a light ring is formed after the lens plane, interfering in the fringes formation. So a little component was used in the top of the lens holder to block the light that was going directly to the lens border. These two components are shown in figure below.</p>\n\n<p align=\"center\">\n<img src=\"/images/components_designed_lens.jpg\" width=\"450\" />\n</p>\n\n<h3 id=\"other-components\">Other Components</h3>\n\n<p>One point that should be taken into account is when the optical components ordered are of different brands. In our case, the beam expander and the laser were acquired from different stores. Because of that, the two components were not compatible to put them together with only one holder. For this, it was ordered more three components to adapt and keep both of them co-linear. The table below outlines these components.</p>\n\n<table>\n <thead>\n <tr>\n <th>Components</th>\n <th>Description</th>\n <th>Brand</th>\n </tr>\n </thead>\n <tbody>\n <tr>\n <td>Adapter</td>\n <td>AD11F - Ø11 mm Cylindrical</td>\n <td>Thorlabs</td>\n </tr>\n <tr>\n <td>Lens Tube</td>\n <td>SM1M15 - 1.5” Long, Two Retaining</td>\n <td>Thorlabs</td>\n </tr>\n <tr>\n <td>Adapter</td>\n <td>SM1A10 - External SM1 Threads <br /> Internal C-Mount Threads</td>\n <td>Thorlabs</td>\n </tr>\n <tr>\n <td>Adapter</td>\n <td>Female M22 x 0.75 to Male</td>\n <td>EdmundOptics</td>\n </tr>\n </tbody>\n</table>\n\n<h3 id=\"pumping-module\">Pumping Module</h3>\n\n<p>In order to make easier the water sample collection, it was designed a pumping module. Composed of one pump, one controller, and both the inlet and outlet tubes, the sample can be inserted into the system with a bi-directional controlled flow.</p>\n\n<table>\n <thead>\n <tr>\n <th>Components</th>\n <th>Description</th>\n </tr>\n </thead>\n <tbody>\n <tr>\n <td>Pump</td>\n <td>Peristaltic Pump - 6-12 VDC Input</td>\n </tr>\n <tr>\n <td>Controller</td>\n <td>Regulator - 12VDC Input</td>\n </tr>\n <tr>\n <td>In/Outlets</td>\n <td>Diameter of 1 mm</td>\n </tr>\n </tbody>\n</table>\n","dir":"/holsys_hardware/","name":"components.md","path":"holsys_hardware/components.md","url":"/holsys_hardware/components.html"},{"sort":2,"layout":"default","title":"Processing","content":"<h1 id=\"processing\">Processing</h1>\n\n<p>Once the image was acquired, it can be processed by applying some transformations to delete some undesirable areas, change the size, apply bright and contrast masks, and crop the image that will be reconstructed. This step can be skipped if the acquired image is already right to be reconstructed. Generally, saved data in mat files can be directly reconstructed, without necessarily making changes to the image.</p>\n\n<p align=\"center\">\n<img src=\"/images/processing_screen.png\" width=\"900\" />\n</p>\n\n<p>All this step is made directly in the browser, using the <a href=\"https://konvajs.org/\">API Konva.js</a>. This API is a powerful tool to work with images in web applications, due to facilities to manipulate them. It’s possible to apply different kinds of transformations, masks, events, animations, and others, with an object-oriented Javascript API.</p>\n","dir":"/hs_webapp/","name":"processing.md","path":"hs_webapp/processing.md","url":"/hs_webapp/processing.html"},{"sort":2,"permalink":"/installation/","layout":"default","title":"Get Started","content":"<h1 id=\"get-started\">Get Started</h1>\n\n<p>The web application was developed through <a href=\"\">Flask Framework</a> and can run locally.</p>\n\n<h2 id=\"environment\">Environment</h2>\n<p>First, we really recommend to create a environment to protect other projects and to install the correct library versions. To do so, install the venv package using pip</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>python3 -m pip install --user virtualenv\n</code></pre>  </div></div>\n\n<p>Once the virtualenv is installed, create a virtual environment</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>python3 -m venv /path/to/new/virtual/environment\n</code></pre>  </div></div>\n\n<p>Finally, go to the correct folder and activate the environment</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>cd /path/to/new/virtual/environment\n. bin/activate\n</code></pre>  </div></div>\n\n<h2 id=\"git-clone\">Git Clone</h2>\n\n<p>Clone this repository</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>git clone https://github.com/andouglasjr/HSapplication/tree/master\n</code></pre>  </div></div>\n\n<h2 id=\"requirements\">Requirements</h2>\n<p>In the requirements.txt files you will find all the libraries with their respects versions to make the application work properly. Run the follow command</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>pip install -r requirements.txt\n</code></pre>  </div></div>\n\n<h2 id=\"running-flask-server\">Running Flask Server</h2>\n<p>Once the requirements have been installed, go to the root directory and run</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>python run.py\n</code></pre>  </div></div>\n\n<p>It will be shown the local ip to access the server in web browser.</p>\n\n<h2 id=\"some-considerations\">Some considerations</h2>\n<ol>\n <li>The reconstruction step uses a modified version of Holopy. This modification is the separation of the propagation method in order to use the spatial filtering. Please, use the holopy available in the git repository available in this application.</li>\n <li>The machine learning models supported by the application are Resnet, Densenet, SENet and EfficientNet. If you will use another kind of network, please install the equivalent library to the environment.</li>\n</ol>\n","dir":"/installation/","name":"README.md","path":"installation/README.md","url":"/installation/"},{"sort":3,"permalink":"/holsys_hardware/","layout":"default","title":"HolSys Hardware","content":"<h1 id=\"holsys-hardware\">HolSys Hardware</h1>\n\n<ul>\n <li><a href=\"/holsys_hardware/knowing_system.html\">Knowing the System</a></li>\n <li><a href=\"/holsys_hardware/components.html\">Components</a></li>\n</ul>\n","dir":"/holsys_hardware/","name":"README.md","path":"holsys_hardware/README.md","url":"/holsys_hardware/"},{"sort":3,"layout":"default","title":"Reconstruction","content":"<h1 id=\"reconstruction\">Reconstruction</h1>\n\n<p>The most important point of the web application is the reconstruction. In this step, the wavelength, pixel size, and the interval of distances in which the propagation must be carried out are requested by the application and saved in the hologram metadata.</p>\n\n<p align=\"center\">\n<img src=\"/images/reconstruction_screen.png\" width=\"900\" />\n</p>\n\n<p>At this point, the user can choose if wants to realize the spatial filter manually, only defining the region of the real image in Fourier space, or performs the reconstruction without this step. This is important because applications with in-line setup use other algorithms to perform this filter. If the user wants to apply a spatial filter, a modal page is open and a crop in the frequency space can be made using <a href=\"https://konvajs.org/\">Konva.js API</a>.</p>\n\n<p>The reconstruction is made using a library developed by Manoharan Lab, Harvard University called <a href=\"https://holopy.readthedocs.io/en/master/\">HoloPy</a>. This library is a python based tool for working with digital holograms and light scattering. It is important to notice that to work properly in a web application same changes have been made directly in the API. Besides that, the spatial filter and autofocus algorithm were implemented since this API has not these implementations. Therefore, <strong>it is important to use the Holopy versions available on the application GitHub, in order to make the system work properly.</strong></p>\n\n<p>This step can take while depending on the hologram image size and the number of planes that will be applied to the propagation. Once the reconstruction is completed and the autofocus finds the best distance Z, the intensity and phase are shown in the browser.</p>\n","dir":"/hs_webapp/","name":"reconstruction.md","path":"hs_webapp/reconstruction.md","url":"/hs_webapp/reconstruction.html"},{"sort":4,"permalink":"/hs_webapp/","layout":"default","title":"HS WebApplication","content":"<h1 id=\"hs-webapplication\">HS WebApplication</h1>\n\n<p>The HS Webapp is able to perform the follow steps:</p>\n\n<ul>\n <li><a href=\"/hs_webapp/acquisition.html\">Acquisition</a></li>\n <li><a href=\"/hs_webapp/processing.html\">Processing</a></li>\n <li><a href=\"/hs_webapp/reconstruction.html\">Reconstruction</a></li>\n <li><a href=\"/hs_webapp/segmentation.html\">Segmentation</a></li>\n <li><a href=\"/hs_webapp/classification.html\">Classification</a></li>\n <li><a href=\"/hs_webapp/generate_stl.html\">Generate STL File</a></li>\n</ul>\n","dir":"/hs_webapp/","name":"README.md","path":"hs_webapp/README.md","url":"/hs_webapp/"},{"sort":4,"layout":"default","title":"Segmentation","content":"<h1 id=\"segmentation\">Segmentation</h1>\n\n<p>In developing…</p>\n","dir":"/hs_webapp/","name":"segmentation.md","path":"hs_webapp/segmentation.md","url":"/hs_webapp/segmentation.html"},{"sort":5,"permalink":"/credits/","layout":"default","title":"Credits and Citations","content":"<h1 id=\"credits-and-citations\">Credits and Citations</h1>\n\n<p>The HolSys_Hardware and the HS_WebApp can be used for free for scientific proposes, regarding the citation of them in those works. We remind you that all the system demonstrated in this web page are ina beta version and can not work one hundred percentage yet.</p>\n\n<p>For anyone that to use the HolSys_Hardware and HS_WebApp we very appreciate if send us feedbacks, suggestions and critics. Then, we can work on the improvement of the functionalities of the system.</p>\n\n<p>Please, if you use these systems considering to cite some of these works:</p>\n\n<ol>\n <li>\n <p>Teresa Cacace, Vittorio Bianco, Biagio Mandracchia, Vito Pagliarulo, Emilia Oleandro, Melania Paturzo, and Pietro Ferraro, “Compact off-axis holographic slide microscope: design guidelines,” Biomed. Opt. Express 11, 2511-2532 (2020)</p>\n </li>\n <li>\n <p>Memmolo, P.; Carcagnì, P.; Bianco, V.; Merola, F.; Goncalves da Silva Junior, A.; Garcia Goncalves, L.M.; Ferraro, P.; Distante, C. Learning Diatoms Classification from a Dry Test Slide by Holographic Microscopy. Sensors 2020, 20, 6353.</p>\n </li>\n <li>\n <p>Pasquale Memmolo, Vittorio Bianco, Pierluigi Carcagnì, Andouglas Goncalves da Silva Junior , Luiz Marcos Garcia Goncalves, Francesco Merola, Melania Paturzo, Cosimo Distante, Pietro Ferraro, “Identification and classification of biological micro-organisms by holographic learning,” Proc. SPIE 11060, Optical Methods for Inspection, Characterization, and Imaging of Biomaterials IV, 110600H (21 June 2019); https://doi.org/10.1117/12.2527484</p>\n </li>\n</ol>\n","dir":"/credits/","name":"README.md","path":"credits/README.md","url":"/credits/"},{"sort":5,"layout":"default","title":"Classification","content":"<h1 id=\"classification\">Classification</h1>\n\n<p>Finally, in the classification step is possible to choose the models and images that will be used to make the classification. The selected options made by the user are sent to the server that used the trained models contained in ML_models folder to perform the classification.</p>\n\n<p>If more than one model is selected, so the system uses an ensemble learning technique to make the classification and return the probabilities vector (the softmax output) to be shown in the application.</p>\n\n<p>As the training as the test was made using PyTorch framework. This framework was developed to be used in the machine learning approach, having several APIs that make easier the development of this kind of application.</p>\n\n<p>To exemplify, it was performed a diatoms classification task. The screenshot shown below is this application. The models used were EfficientNet_B0, EfficientNet_B1 and SEResnet50. The selected image and the classification results are also indicated in the figure.</p>\n\n<p align=\"center\">\n<img src=\"/images/classification_screen.png\" width=\"900\" />\n</p>\n\n","dir":"/hs_webapp/","name":"classification.md","path":"hs_webapp/classification.md","url":"/hs_webapp/classification.html"},{"sort":6,"layout":"default","title":"Generate STL File","content":"<h1 id=\"generate-stl-file\">Generate STL File</h1>\n\n<p>One interesting function of the web application is to generate a 3D microscope stl file that can be printed and used in a specific application. Once the system setup was made and the reconstruction step works, the distances between grating and lens, and lens and camera, can be used in that specific configuration to that samples that were tested before. In this case, passing these parameters, the HS-WebApp generates automatically the 3D device in the STL_Files folder.</p>\n\n<p align=\"center\">\n<img src=\"/images/generation_stl_screen.png\" width=\"900\" />\n</p>\n\n<p>The 3D microscope is based on the work of Teresa Cacace published <a href=\"https://www.osapublishing.org/boe/fulltext.cfm?uri=boe-11-5-2511&amp;id=430110\">here</a>.The generated file is a STL file as shown in the figure below.</p>\n\n<p align=\"center\">\n<img src=\"/images/microscope.png\" width=\"160\" />\n<img src=\"/images/microscope_1.png\" width=\"200\" />\n</p>\n","dir":"/hs_webapp/","name":"generate_stl.md","path":"hs_webapp/generate_stl.md","url":"/hs_webapp/generate_stl.html"}]